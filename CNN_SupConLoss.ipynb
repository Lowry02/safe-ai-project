{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiZjBFb9YkHc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SupCon(nn.Module):\n",
        "    def __init__(self, temperature=0.07):\n",
        "        super(SupCon, self).__init__()\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, features, labels):\n",
        "        \"\"\"\n",
        "        features: Tensor of shape (B, D), where B is the batch size and D is the size of the embeddings?\n",
        "        labels:   Tensor of shape (B,)\n",
        "        \"\"\"\n",
        "        \n",
        "        device = features.device\n",
        "        # normalize embeddings, so sim(z_i, z_j) = z_i ⋅ z_j\n",
        "        features = F.normalize(features)\n",
        "        # similarity matrix (cosine similarity) -> sim_ij = z_i ⋅ z_j / τ\n",
        "        sim_matrix = torch.matmul(features, features.T) / self.temperature # shape: (B, B)\n",
        "\n",
        "        # create label mask\n",
        "        labels = labels.contiguous().view(-1, 1) # make sure this tensor is laid out correctly in memory, then reshape it from (B,) to (B, 1) -> column vector\n",
        "        mask = torch.eq(labels, labels.T).float().to(device) # mask[i, j] = 1 if same class, else 0\n",
        "        # -> torch.eq basically creates a matrix by comparing y_i and y_j, where we use labels.T to obtain a square matrix of shape (B, B)\n",
        "        # remove self-comparisons\n",
        "        logits_mask = torch.ones_like(mask)\n",
        "        logits_mask.fill_diagonal_(0) # -> mask[i, i] = 0\n",
        "        mask = mask * logits_mask\n",
        "\n",
        "        # compute log-softmax over rows\n",
        "        logits = sim_matrix - torch.max(sim_matrix, dim=1, keepdim=True)[0]\n",
        "        exp_logits = torch.exp(logits) * logits_mask\n",
        "        log_prob = logits - torch.log(exp_logits.sum(dim=1, keepdim=True))\n",
        "\n",
        "        # average over positives\n",
        "        mask_sum = mask.sum(dim=1)\n",
        "        mask_sum = torch.clamp(mask_sum, min=1.0)\n",
        "        mean_log_prob_pos = (mask * log_prob).sum(dim=1) / mask_sum\n",
        "\n",
        "        loss = -mean_log_prob_pos.mean()\n",
        "        return loss\n",
        "\n",
        "\n",
        "class CombinedLoss(nn.Module):\n",
        "    def __init__(self, alpha = 0.2):\n",
        "        super(CombinedLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.entropy_loss = nn.CrossEntropyLoss()\n",
        "        self.supcon_loss = SupCon()\n",
        "\n",
        "    def forward(self, embeddings, outputs, labels):\n",
        "        return self.entropy_loss(outputs, labels) * (1 - self.alpha) + self.supcon_loss(embeddings, labels) * self.alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGZb-4AcY1Af"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels = 3, num_classes = 10, proj_dim = 128):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "\n",
        "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "\n",
        "        self.projector = nn.Sequential(\n",
        "            nn.Linear(256 * 4 * 4, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, proj_dim),\n",
        "            nn.BatchNorm1d(proj_dim)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(proj_dim, proj_dim*4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(proj_dim*4, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        \n",
        "        proj = self.projector(x)      # for SupCon\n",
        "        logits = self.classifier(proj)   # for CE\n",
        "\n",
        "        return proj, logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0s8fbsyzMUF"
      },
      "source": [
        "------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzooQDi8Y5LW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiCH1cVxZadH"
      },
      "outputs": [],
      "source": [
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        # NVIDIA GPU\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(f\"Using CUDA: {torch.cuda.get_device_name(0)}\")\n",
        "    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
        "        # Apple Silicon GPU (MPS)\n",
        "        device = torch.device(\"mps\")\n",
        "        print(\"Using MPS (Apple Silicon GPU)\")\n",
        "    else:\n",
        "        # Fallback to CPU\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"Using CPU\")\n",
        "    return device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPGo5FDrZb15",
        "outputId": "f023e880-59e1-4fbb-dd7e-8e2a553e2876"
      },
      "outputs": [],
      "source": [
        "DEVICE = get_device()\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfIHtNRrZdFE"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # TODO: add transformations/augmentations?\n",
        "\"\"\"\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),        # randomly flip the image horizontally\n",
        "    transforms.RandomRotation(15),                 # randomly rotate the image by ±15 degrees\n",
        "    transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),  # random crop and resize to 32x32\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # adjust colors\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "dataset = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=transform)\n",
        "\n",
        "train_ratio, validation_ratio = 0.8, 0.2\n",
        "dataset_size = len(dataset)\n",
        "train_size = int(train_ratio * dataset_size)\n",
        "validation_size = dataset_size - train_size\n",
        "\n",
        "train_dataset, validation_dataset = random_split(dataset, [train_size, validation_size])\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
        "\n",
        "test_data = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
        "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDrsGDNhZhFT"
      },
      "outputs": [],
      "source": [
        "model = CNN().to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyH0MwqVZnyu"
      },
      "outputs": [],
      "source": [
        "cross_entropy_loss = nn.CrossEntropyLoss()\n",
        "sup_con_loss = SupCon()\n",
        "total_step = len(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRrD729F_T8A"
      },
      "outputs": [],
      "source": [
        "# training the CNN only\n",
        "\n",
        "# disabling classifier weights update\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8sLsSnBz3GF",
        "outputId": "5b3d44e1-4697-4237-9282-189087d7c4f1"
      },
      "outputs": [],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for i, (images, labels) in enumerate(train_loader): # iterating over all the batches\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        embeddings, _ = model(images)\n",
        "        loss = sup_con_loss(embeddings, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        validation_loss = 0\n",
        "        for images, labels in validation_loader:\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            embeddings, _ = model(images)\n",
        "            loss = sup_con_loss(embeddings, labels)\n",
        "            validation_loss += loss.item()\n",
        "\n",
        "    validation_loss /= len(validation_loader)\n",
        "\n",
        "    print(f\"> Epoch {epoch+1}/{EPOCHS}\")\n",
        "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
        "    print(f\"  Validation Loss: {validation_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6soguUgXCOzn"
      },
      "outputs": [],
      "source": [
        "# training the CLASSIFIER only\n",
        "\n",
        "# enabling only classifier weights update\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "ZR_rC88_0lBp",
        "outputId": "f1fc3662-bf46-4ac7-b492-fbc43d002e97"
      },
      "outputs": [],
      "source": [
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    train_accuracy = 0\n",
        "    for i, (images, labels) in enumerate(train_loader): # iterating over all the batches\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        _, logits = model(images)\n",
        "        loss = cross_entropy_loss(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        train_accuracy += (torch.argmax(logits, dim=1) == labels).sum().item() / len(labels)\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    train_accuracy = train_accuracy / len(train_loader) * 100\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        validation_loss = 0\n",
        "        validation_accuracy = 0\n",
        "        for images, labels in validation_loader:\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            _, logits = model(images)\n",
        "            loss = cross_entropy_loss(logits, labels)\n",
        "            validation_loss += loss.item()\n",
        "            validation_accuracy += (torch.argmax(logits, dim=1) == labels).sum().item() / len(labels)\n",
        "\n",
        "    validation_loss /= len(validation_loader)\n",
        "    validation_accuracy = validation_accuracy / len(validation_loader) * 100\n",
        "\n",
        "\n",
        "    print(f\"> Epoch {epoch+1}/{EPOCHS}\")\n",
        "    print(f\"  Training loss      : {train_loss:.4f}, Training accuracy  : {train_accuracy:.2f}%\")\n",
        "    print(f\"  Validation loss    : {validation_loss:.4f}, Validation accuracy: {validation_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPdXD86gbhg4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
