{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83cdf670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8cc31f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding complete_verifier to sys.path\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import torch\n",
    "from model import CNNCrown, CNN, Encoder, LinearClassifier\n",
    "from verifier import ABCrown\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e82315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(in_channels=3, proj_dim=128)\n",
    "encoder.load_state_dict(torch.load(\"./model_weights/no_augmentation/encoder_weights.pt\", map_location=\"cpu\"))\n",
    "classifier = LinearClassifier(in_dim=128, num_classes=10)\n",
    "classifier.load_state_dict(torch.load(\"./model_weights/no_augmentation/classifier_weights.pt\", map_location=\"cpu\"))\n",
    "cnn = CNN.import_from(encoder, classifier)\n",
    "torch.save(cnn.state_dict(), \"./model_weights/no_augmentation/contrastive_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9ba060",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weigths_file = \"./model_weights/no_augmentation/contrastive_model.pt\"\n",
    "log_file_name = \"custom_model.csv\"\n",
    "n_images = 1   # number of images to test\n",
    "epsilon_list = torch.tensor([1/255, 2/255, 4/255, 8/255, 16/255])\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f112f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model\n",
    "n_classes = 10\n",
    "image_dimension = (3, 32, 32)\n",
    "net = CNNCrown(image_dimension[0], n_classes)\n",
    "net.load_state_dict(torch.load(model_weigths_file, map_location=device))\n",
    "net = net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c2af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the images\n",
    "torch.manual_seed(42)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "images_dataset = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=ToTensor())\n",
    "selected_images = []\n",
    "\n",
    "#Â select images that are corrctly classified\n",
    "for i in range(len(images_dataset)):\n",
    "    image, label = images_dataset[i]\n",
    "    logits = net(image.unsqueeze(0))\n",
    "    prediction = torch.argmax(logits, dim=1)[0].item()\n",
    "    if prediction == label:\n",
    "            selected_images.append((image, label))\n",
    "            \n",
    "    if len(selected_images) == n_images:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e3f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the verifier\n",
    "verifier = ABCrown(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f1f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_adversarial_example = -torch.ones_like(selected_images[0][0]).to(device)  # when an error occurs or no adversarial images are found, a Tensor with -1s is saved\n",
    "\n",
    "# opening the csv\n",
    "with open(log_file_name, mode=\"w\", newline=\"\") as file:\n",
    "    # writing the header\n",
    "    writer = csv.DictWriter(file, fieldnames=['image_id', 'eps', 'status', 'success'])\n",
    "    writer.writeheader()\n",
    "    adversarial_examples = []\n",
    "    # iterating through the images\n",
    "    for i, (image, label) in enumerate(selected_images):\n",
    "        adversarial_example_per_image = []\n",
    "        # iterating thtough the epsilons\n",
    "        for eps in epsilon_list:\n",
    "            # if there is an error, don't crash\n",
    "            result = None\n",
    "            try:\n",
    "                result = verifier.verify(net, image, n_classes, label, eps.item()).as_dict()\n",
    "            except Exception as error:\n",
    "                # save a dummy tensor (all -1s)\n",
    "                print(f\"> Error at image {i} and eps={eps}: {error}\")\n",
    "                info_to_save = {\n",
    "                    \"image_id\": i,\n",
    "                    \"eps\": eps.item(),\n",
    "                    \"status\": \"CRASH\",\n",
    "                    \"success\": False,\n",
    "                }\n",
    "                adversarial_example_per_image.append(error_adversarial_example)\n",
    "                writer.writerow(info_to_save)\n",
    "                file.flush()\n",
    "            \n",
    "            if result is not None:\n",
    "                # saving result\n",
    "                info_to_save = {\n",
    "                    \"image_id\": i,\n",
    "                    \"eps\": eps.item(),\n",
    "                    \"status\": result['status'],\n",
    "                    \"success\": result['success'],\n",
    "                }\n",
    "                writer.writerow(info_to_save)\n",
    "                file.flush()\n",
    "                \n",
    "                # saving adversarial example\n",
    "                if result['stats']['attack_examples'].shape[0] != 0:\n",
    "                    adversarial_example_per_image.append(result['stats']['attack_examples'][0])\n",
    "                else:\n",
    "                    adversarial_example_per_image.append(error_adversarial_example)\n",
    "                \n",
    "        adversarial_examples.append(torch.stack(adversarial_example_per_image))\n",
    "\n",
    "# saving the obtained adversarial examples\n",
    "adversarial_examples = torch.stack(adversarial_examples)\n",
    "torch.save(adversarial_examples, \"adversarial_examples.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d412b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the adversarial examples\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the selected image and its label\n",
    "selected_image, label = selected_images[0]\n",
    "\n",
    "# Extract the adversarial examples for the selected image\n",
    "adversarial_examples_for_image = adversarial_examples[0]\n",
    "\n",
    "# Plot the original image\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, len(adversarial_examples_for_image) + 1, 1)\n",
    "plt.imshow(selected_image.permute(1, 2, 0).numpy())\n",
    "plt.title(f\"Original Image (Label: {label})\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot the adversarial examples\n",
    "for idx, adv_example in enumerate(adversarial_examples_for_image):\n",
    "    plt.subplot(1, len(adversarial_examples_for_image) + 1, idx + 2)\n",
    "    plt.imshow(adv_example.permute(1, 2, 0).detach().cpu().numpy())\n",
    "    plt.title(f\"Adversarial Example {idx + 1}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
