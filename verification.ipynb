{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the needed modules and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T02:29:51.906558Z",
     "iopub.status.busy": "2026-01-26T02:29:51.906076Z",
     "iopub.status.idle": "2026-01-26T02:29:51.910285Z",
     "shell.execute_reply": "2026-01-26T02:29:51.909470Z",
     "shell.execute_reply.started": "2026-01-26T02:29:51.906531Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from auto_LiRPA import BoundedModule\n",
    "from model import CNNCrown, Encoder, LinearClassifier\n",
    "from verifier import ABCrown, PGDVerifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "BATCH_SIZE = 2048\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T02:31:18.979348Z",
     "iopub.status.busy": "2026-01-26T02:31:18.978893Z",
     "iopub.status.idle": "2026-01-26T02:31:20.759087Z",
     "shell.execute_reply": "2026-01-26T02:31:20.758160Z",
     "shell.execute_reply.started": "2026-01-26T02:31:18.979320Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "dataset = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=transform)\n",
    "\n",
    "train_ratio, validation_ratio = 0.8, 0.2\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(train_ratio * dataset_size)\n",
    "validation_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, validation_dataset = random_split(dataset, [train_size, validation_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, load all the trained models on the `DEVICE`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T02:31:18.734775Z",
     "iopub.status.busy": "2026-01-26T02:31:18.733906Z",
     "iopub.status.idle": "2026-01-26T02:31:18.977545Z",
     "shell.execute_reply": "2026-01-26T02:31:18.976829Z",
     "shell.execute_reply.started": "2026-01-26T02:31:18.734738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_path = \"models_info/model_weights\"\n",
    "augmentation_path = f\"{base_path}/augmentation\"\n",
    "no_augmentation_path = f\"{base_path}/no_augmentation\"\n",
    "\n",
    "# loading no certified models\n",
    "models_weights = [\n",
    "    torch.load(f\"{augmentation_path}/normal_model.pt\", map_location=DEVICE),\n",
    "    torch.load(f\"{augmentation_path}/contrastive_model.pt\", map_location=DEVICE),\n",
    "    torch.load(f\"{augmentation_path}/adversarial_model.pt\", map_location=DEVICE),\n",
    "    torch.load(f\"{augmentation_path}/adversarial_contrastive_model.pt\", map_location=DEVICE),\n",
    "    torch.load(f\"{no_augmentation_path}/normal_model.pt\", map_location=DEVICE),\n",
    "    torch.load(f\"{no_augmentation_path}/contrastive_model.pt\", map_location=DEVICE),\n",
    "    torch.load(f\"{no_augmentation_path}/adversarial_model.pt\", map_location=DEVICE),\n",
    "    torch.load(f\"{no_augmentation_path}/adversarial_contrastive_model.pt\", map_location=DEVICE),\n",
    "]\n",
    "\n",
    "models = []\n",
    "\n",
    "for weights in models_weights:\n",
    "    model = CNNCrown(pooling=False)\n",
    "    model.load_state_dict(weights)\n",
    "    model.to(DEVICE)\n",
    "    models.append(model)\n",
    "    \n",
    "# loading certified models by hand\n",
    "\n",
    "# with augmentation\n",
    "certified_encoder = BoundedModule(Encoder(), torch.empty(2, 3, 32, 32))\n",
    "certified_encoder.load_state_dict(torch.load(f\"{augmentation_path}/certified_contrastive_encoder.pt\"))\n",
    "certified_classifier = LinearClassifier()\n",
    "certified_classifier.load_state_dict(torch.load(f\"{augmentation_path}/certified_contrastive_classifier.pt\"))\n",
    "certified_contrastive_model = CNNCrown()\n",
    "certified_contrastive_model.encoder = certified_encoder\n",
    "certified_contrastive_model.classifier = certified_classifier\n",
    "models[4:4] = [certified_contrastive_model]    # the models trained using augmentation are in the first part of the list\n",
    "\n",
    "certified_model = BoundedModule(CNNCrown(), torch.empty(2, 3, 32, 32))\n",
    "certified_model.load_state_dict(torch.load(f\"{augmentation_path}/certified_model.pt\"))\n",
    "models[4:4] = [certified_model]    # the models trained using augmentation are in the first part of the list\n",
    "\n",
    "# no augmentation\n",
    "certified_model = BoundedModule(CNNCrown(), torch.empty(2, 3, 32, 32))\n",
    "certified_model.load_state_dict(torch.load(f\"{no_augmentation_path}/certified_model.pt\"))\n",
    "certified_model.to(DEVICE)\n",
    "models.append(certified_model)    # the models trained using no augmentation are in the last part of the list\n",
    "\n",
    "certified_encoder = BoundedModule(Encoder(), torch.empty(2, 3, 32, 32))\n",
    "certified_encoder.load_state_dict(torch.load(f\"{no_augmentation_path}/certified_contrastive_encoder.pt\"))\n",
    "certified_classifier = LinearClassifier()\n",
    "certified_classifier.load_state_dict(torch.load(f\"{no_augmentation_path}/certified_contrastive_classifier.pt\"))\n",
    "certified_contrastive_model = CNNCrown()\n",
    "certified_contrastive_model.encoder = certified_encoder\n",
    "certified_contrastive_model.classifier = certified_classifier\n",
    "certified_contrastive_model.to(DEVICE)\n",
    "models.append(certified_contrastive_model)    # the models trained using no augmentation are in the last part of the list\n",
    "\n",
    "\n",
    "models_name = [\"Normal Model\", \"Contrastive Model\", \"Adversarial Model\", \"Adversarial Contrastive\", \"Certified\", \"Certified Contrastive\"] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_list = [1/255, 2/255, 4/255, 8/255, 16/255]\n",
    "epsilon_labels = [\"1/255\", \"2/255\", \"4/255\", \"8/255\", \"16/255\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PGD Verifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, evaluate the robustness of multiple models against a PGD adversarial attack by computing the **Attack Success Rate (ASR)** for different perturbation magnitudes (Îµ). ASR is measured as the percentage of originally correctly classified images that are successfully misclassified after the attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T02:31:20.760882Z",
     "iopub.status.busy": "2026-01-26T02:31:20.760540Z",
     "iopub.status.idle": "2026-01-26T02:42:07.935034Z",
     "shell.execute_reply": "2026-01-26T02:42:07.933630Z",
     "shell.execute_reply.started": "2026-01-26T02:31:20.760847Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# PGD attack only\n",
    "pgd = PGDVerifier(DEVICE)\n",
    "\n",
    "print(\"> ASR = Attack Success Rate\\n\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for epsilon, eps_label  in zip(epsilon_list, epsilon_labels):\n",
    "        print(f\"> Eps: {eps_label}\")\n",
    "        for model, model_name in zip(models, models_name): \n",
    "            model.eval()\n",
    "            print(f\"\\t> {model_name}\")\n",
    "            \n",
    "            test_adv_attack_success = 0\n",
    "            total_images = 0\n",
    "            for i, (images, labels) in enumerate(train_loader):\n",
    "                images = images.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "                adversarial_examples, successes, initial_wrong_predictions = pgd.verify(\n",
    "                    model, \n",
    "                    images, \n",
    "                    labels, \n",
    "                    epsilon=epsilon, \n",
    "                    clamp_min=-1, # clamp_* -> ensure valid input within [-1,1]\n",
    "                    clamp_max=1\n",
    "                )      \n",
    "                test_adv_attack_success += successes.sum().item()\n",
    "                total_images += successes.shape[0] - initial_wrong_predictions.sum().item()\n",
    "                    \n",
    "            test_adv_attack_success /= total_images\n",
    "            test_adv_attack_success *= 100\n",
    "            print(f\"\\t\\t- Test ASR: {test_adv_attack_success}%;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\alpha\\beta$-CROWN Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_POINTS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifier = ABCrown(DEVICE)\n",
    "\n",
    "outputs = [[] for _ in models[:4]]\n",
    "epsilon_index = 0 \n",
    "\n",
    "for model_id, model in enumerate(models[:4]):\n",
    "    model.eval()\n",
    "    model = model.to(DEVICE)\n",
    "    for i in range(len(test_dataset)):\n",
    "        image, label = test_dataset[i]\n",
    "        image = image.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            logits = model(image.unsqueeze(0))[0]\n",
    "        prediction = torch.argmax(logits)\n",
    "        \n",
    "        if prediction == label:\n",
    "            result = verifier.verify(model, image, 10, label, epsilon_list[epsilon_index])\n",
    "            outputs[model_id].append(result.status)\n",
    "            print(\"QUA\", models_name[model_id], len(outputs[model_id]), result.status)\n",
    "\n",
    "        if len(outputs[model_id]) >= MAX_POINTS:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all possible labels\n",
    "all_labels = ['safe', 'verified', 'unsafe-pgd', 'unsafe-bab', 'safe-incomplete', 'unknown']\n",
    "label_indices = range(len(all_labels))\n",
    "\n",
    "for model_id, output in enumerate(outputs[:4]):\n",
    "    # Map outputs to indices based on all_labels\n",
    "    output_indices = [all_labels.index(label) for label in output]\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(output_indices, bins=range(len(all_labels) + 1), align='left', rwidth=0.8)\n",
    "    plt.title(f\"Histogram of Labels for Model {models_name[model_id]}\")\n",
    "    plt.xlabel(\"Labels\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xticks(label_indices, all_labels, rotation=45)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the frequency of statuses for each model\n",
    "status_frequency = {}\n",
    "\n",
    "# Iterate over the outputs and models_name\n",
    "for model_name, output in zip(models_name[:4], outputs[:4]):\n",
    "    # Count the frequency of each status in the output\n",
    "    status_frequency[model_name] = dict(Counter(output))\n",
    "\n",
    "print(status_frequency)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelId": 569571,
     "modelInstanceId": 557013,
     "sourceId": 731160,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
