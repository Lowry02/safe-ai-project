{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8cc31f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from model import Net\n",
    "from verifier import ABCrown\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c9ba060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10cfbfa30>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weigths_file = \"./ex_model.pt\"\n",
    "log_file_name = \"try.csv\"\n",
    "n_images = 2   # number of images to test\n",
    "epsilon_list = torch.linspace(0, 0.5, 5)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47f112f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model\n",
    "n_classes = 10\n",
    "image_dimension = (3, 32, 32)\n",
    "net = Net(image_dimension[0], n_classes)\n",
    "net.load_state_dict(torch.load(model_weigths_file))\n",
    "net = net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c4c2af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the images\n",
    "images_dataset = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=ToTensor())\n",
    "image_indexes = torch.randint(0, len(images_dataset), (n_images,), dtype=torch.int)\n",
    "selected_images = ([images_dataset[i] for i in image_indexes])  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8e3f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the verifier\n",
    "verifier = ABCrown(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f1f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 284.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Error at image 0 and eps=0.0\n",
      "> Error at image 0 and eps=0.125\n",
      "> Error at image 0 and eps=0.25\n",
      "> Error at image 0 and eps=0.375\n",
      "> Error at image 0 and eps=0.5\n",
      "> Error at image 1 and eps=0.0\n",
      "> Error at image 1 and eps=0.125\n",
      "> Error at image 1 and eps=0.25\n",
      "> Error at image 1 and eps=0.375\n",
      "> Error at image 1 and eps=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# opening the csv\n",
    "with open(log_file_name, mode=\"w\", newline=\"\") as file:\n",
    "    # writing the header\n",
    "    writer = csv.DictWriter(file, fieldnames=['image_id', 'eps', 'status', 'success'])\n",
    "    writer.writeheader()\n",
    "    adversarial_examples = []\n",
    "    # iterating through the images\n",
    "    for i, (image, label) in tqdm(enumerate(selected_images)):\n",
    "        adversarial_example_per_image = []\n",
    "        # iterating thtough the epsilons\n",
    "        for eps in epsilon_list:\n",
    "            # if there is an error, don't crash\n",
    "            try:\n",
    "                result = verifier.verify(net, image, n_classes, label, eps.item()).as_dict()\n",
    "            except:\n",
    "                # save a dummy tensor (all -1s)\n",
    "                print(f\"> Error at image {i} and eps={eps}\")\n",
    "                info_to_save = {\n",
    "                    \"image_id\": i,\n",
    "                    \"eps\": eps.item(),\n",
    "                    \"status\": \"CRASH\",\n",
    "                    \"success\": False,\n",
    "                }\n",
    "                adversarial_example_per_image.append(-torch.ones_like(image))\n",
    "                writer.writerow(info_to_save)\n",
    "                file.flush()\n",
    "                pass\n",
    "            \n",
    "            # saving result\n",
    "            info_to_save = {\n",
    "                \"image_id\": i,\n",
    "                \"eps\": eps.item(),\n",
    "                \"status\": result['status'],\n",
    "                \"success\": result['success'],\n",
    "            }\n",
    "            writer.writerow(info_to_save)\n",
    "            file.flush()\n",
    "            \n",
    "            # saving adversarial example\n",
    "            if result['stats']['attack_examples'].shape[0] != 0:\n",
    "                adversarial_example_per_image.append(result['stats']['attack_examples'][0])\n",
    "            else:\n",
    "                adversarial_example_per_image.append(-torch.ones_like(image))\n",
    "                \n",
    "        adversarial_examples.append(torch.stack(adversarial_example_per_image))\n",
    "\n",
    "# saving the obtained adversarial examples\n",
    "torch.save(torch.stack(adversarial_examples), \"adversarial_examples.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3377c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
