{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf3cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c23e787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Net\n",
    "from supconloss import SupCon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f0a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc61658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add transformations/augmentations/normalisation\n",
    "training_data = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "# TODO: divide into train and valid\n",
    "\n",
    "test_data = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8288c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it = iter(train_loader) # create an iterator over the DataLoader\n",
    "# first = next(it)\n",
    "# print(first[1]) # in position [1], we get the vector of the labels of the batch\n",
    "# second = next(it)\n",
    "# print(second[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9526780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"Airplane\",\n",
    "    1: \"Automobile\",\n",
    "    2: \"Bird\",\n",
    "    3: \"Cat\",\n",
    "    4: \"Deer\",\n",
    "    5: \"Dog\",\n",
    "    6: \"Frog\",\n",
    "    7: \"Horse\",\n",
    "    8: \"Ship\",\n",
    "    9: \"Truck\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5803fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae24f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.dataset.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72b1677",
   "metadata": {},
   "source": [
    "`training_data` is the Dataset, whereas `train_loader` is the wrapper around the Dataset and it controls how data is delivered by creating mini-batches, shuffling, workers, iterating, ... $\\rightarrow$ `train_loader.dataset` is the Dataset  \n",
    "The dataset is composed of pairs of (image, class), where the image is a matrix of pixels and the class $\\in \\{0,9\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d857c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.dataset[15][1] # class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355dd019",
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_model = Net().to(DEVICE)\n",
    "combined_model = Net().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670be792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer1 = optim.SGD(classic_model.parameters(), lr=0.01, momentum = 0.9)\n",
    "optimizer2 = optim.SGD(combined_model.parameters(), lr=0.01, momentum = 0.9)\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "criterion2 = SupCon()\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09e595b",
   "metadata": {},
   "source": [
    "Allora, l'idea e' quella di implementare la contrastive loss. Cio' significa ridurre la distanza tra vettori simili e aumentare la distanza tra vettori diversi $\\rightarrow$ loss in funzione della distanza tra i due vettori: se appartenenti alla stessa classe e bassa distanza, loss bassa, e viceversa\n",
    "Contrastive Loss: $$ L_{i, j} = -\\log \\frac{\\exp(sim(z_i, z_j) / \\tau)}{\\sum_{k\\neq i}\\exp(sim(z_i, z_k) / \\tau)}, \\quad\\quad\\quad \\text{where } sim(z_i, z_j) = \\frac{z_i\\cdot z_j}{||z_i|| \\ ||z_j||} $$\n",
    "\n",
    "SCHERZONE QUESTA Ãˆ la NT-XENT nooooooo  \n",
    "Noi vogliamo la SupCon: $$ \\mathcal L_i = {-1\\over |P(i)|}\\sum_{p\\in P(i)}\\log \\frac{\\exp(sim(z_i, z_p) / \\tau)}{\\sum_{a\\neq i}\\exp(sim(z_i, z_a) / \\tau)}, $$ where $P(i)$ is the set of positives for anchor $i$.\n",
    "$\\rightarrow$ final loss: $$ L = {1\\over B}\\sum_i L_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader): # iterating over all the batches\n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        optimizer1.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = classic_model(images)\n",
    "        loss = criterion1(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, EPOCHS, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db859e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader): # iterating over all the batches\n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        optimizer2.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = combined_model(images)\n",
    "        loss = criterion2(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, EPOCHS, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b179dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        outputs = classic_model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        del images, labels, outputs\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
