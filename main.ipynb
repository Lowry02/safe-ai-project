{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf3cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Sampler, random_split\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c23e787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import CNN\n",
    "from losses import CombinedLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c370d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        # NVIDIA GPU\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"Using CUDA: {torch.cuda.get_device_name(0)}\")\n",
    "    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "        # Apple Silicon GPU (MPS)\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS (Apple Silicon GPU)\")\n",
    "    else:\n",
    "        # Fallback to CPU\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f0a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = get_device()\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b34ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    # spatial\n",
    "    transforms.RandomResizedCrop(size=32, scale=(0.2, 1.0), ratio=(0.75, 1.33)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # color\n",
    "    transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)]),\n",
    "    transforms.RandomGrayscale(),\n",
    "\n",
    "    transforms.GaussianBlur(kernel_size=3),\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2470, 0.2435, 0.2616))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4dd47b",
   "metadata": {},
   "source": [
    "### Random Rampler $\\rightarrow$ Normal DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc61658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=train_transform)\n",
    "validation_dataset = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=test_transform) # different transformations\n",
    "\n",
    "dataset_size = len(train_dataset)\n",
    "train_ratio, validation_ratio = 0.8, 0.2\n",
    "train_size = int(train_ratio * dataset_size)\n",
    "validation_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, _ = random_split(train_dataset, [train_size, validation_size])\n",
    "_, validation_dataset = random_split(validation_dataset, [train_size, validation_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "\n",
    "test_data = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=test_transform)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205b5ae5",
   "metadata": {},
   "source": [
    "### Balanced Sampler $\\rightarrow$ Balanced DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8280d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BalancedBatchSampler(Sampler):\n",
    "#     def __init__(self, labels, batch_size, num_classes):\n",
    "#         self.labels = labels\n",
    "#         self.batch_size = batch_size\n",
    "#         self.num_classes = num_classes\n",
    "\n",
    "#         self.base = batch_size // num_classes\n",
    "#         self.remainder = batch_size % num_classes\n",
    "\n",
    "#         # indices per class\n",
    "#         self.class_indices = defaultdict(list)\n",
    "#         for idx, label in enumerate(labels):\n",
    "#             self.class_indices[label].append(idx)\n",
    "\n",
    "#         self.num_batches = len(labels) // batch_size\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         for _ in range(self.num_batches):\n",
    "#             batch = []\n",
    "\n",
    "#             extra_classes = random.sample(range(self.num_classes), self.remainder) # choose which classes get +1 sample\n",
    "\n",
    "#             for cls in range(self.num_classes):\n",
    "#                 n_samples = self.base + (1 if cls in extra_classes else 0)\n",
    "#                 batch.extend(random.sample(self.class_indices[cls], n_samples))\n",
    "\n",
    "#             random.shuffle(batch)\n",
    "#             yield batch\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48298d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=train_transform)\n",
    "# validation_dataset = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=test_transform) # different transformations\n",
    "\n",
    "# dataset_size = len(train_dataset)\n",
    "# train_ratio, validation_ratio = 0.8, 0.2\n",
    "# train_size = int(train_ratio * dataset_size)\n",
    "# validation_size = dataset_size - train_size\n",
    "\n",
    "# train_dataset, _ = random_split(train_dataset, [train_size, validation_size])\n",
    "# _, validation_dataset = random_split(validation_dataset, [train_size, validation_size])\n",
    "\n",
    "# labels = train_dataset.dataset.targets # array 40k-dim of labels for each sample\n",
    "\n",
    "# sampler = BalancedBatchSampler(labels=labels, batch_size=128, num_classes=10)\n",
    "# train_loader = DataLoader(train_dataset, batch_sampler=sampler, num_workers=8)\n",
    "\n",
    "# validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "\n",
    "# test_data = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=test_transform)\n",
    "# test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3cde52",
   "metadata": {},
   "source": [
    "### Playing with Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386b147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dfa20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dfd970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes = 10\n",
    "# labels = torch.zeros(num_classes, dtype=torch.long)\n",
    "# print(labels)\n",
    "\n",
    "# for _, target in train_dataset.dataset:\n",
    "#     labels[target] += 1\n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b727520",
   "metadata": {},
   "source": [
    "TL;DR: every class has exactly 5000 samples $\\rightarrow$ no need for WeightedSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8288c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it = iter(train_loader) # create an iterator over the DataLoader\n",
    "# first = next(it)\n",
    "# print(first[1]) # in position [1], we get the vector of the labels of the batch\n",
    "# second = next(it)\n",
    "# print(second[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae24f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72b1677",
   "metadata": {},
   "source": [
    "`training_data` is the Dataset, whereas `train_loader` is the wrapper around the Dataset and it controls how data is delivered by creating mini-batches, shuffling, workers, iterating, ... $\\rightarrow$ `train_loader.dataset` is the Dataset  \n",
    "The dataset is composed of pairs of (image, class), where the image is a matrix of pixels and the class $\\in \\{0,9\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d857c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.dataset[15][1] # class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7ad787",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355dd019",
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_model = CNN().to(DEVICE)\n",
    "combined_model = CNN().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670be792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer1 = optim.SGD(classic_model.parameters(), lr=0.01, momentum = 0.9)\n",
    "optimizer2 = optim.SGD(combined_model.parameters(), lr=0.01, momentum = 0.9)\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "criterion2 = CombinedLoss(alpha = 0.5) # TODO: optimise alpha\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09e595b",
   "metadata": {},
   "source": [
    "Allora, l'idea e' quella di implementare la contrastive loss. Cio' significa ridurre la distanza tra vettori simili e aumentare la distanza tra vettori diversi $\\rightarrow$ loss in funzione della distanza tra i due vettori: se appartenenti alla stessa classe e bassa distanza, loss bassa, e viceversa\n",
    "Contrastive Loss: $$ L_{i, j} = -\\log \\frac{\\exp(sim(z_i, z_j) / \\tau)}{\\sum_{k\\neq i}\\exp(sim(z_i, z_k) / \\tau)}, \\quad\\quad\\quad \\text{where } sim(z_i, z_j) = \\frac{z_i\\cdot z_j}{||z_i|| \\ ||z_j||} $$\n",
    "\n",
    "SCHERZONE QUESTA Ãˆ la NT-XENT nooooooo  \n",
    "Noi vogliamo la SupCon: $$ \\mathcal L_i = {-1\\over |P(i)|}\\sum_{p\\in P(i)}\\log \\frac{\\exp(sim(z_i, z_p) / \\tau)}{\\sum_{a\\neq i}\\exp(sim(z_i, z_a) / \\tau)}, $$ where $P(i)$ is the set of positives for anchor $i$.\n",
    "$\\rightarrow$ final loss: $$ L = {1\\over B}\\sum_i L_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader): # iterating over all the batches\n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        optimizer1.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        _, outputs = classic_model(images)\n",
    "        loss = criterion1(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, EPOCHS, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db859e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader): # iterating over all the batches\n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        optimizer2.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        embeddings, outputs = combined_model(images)\n",
    "        loss = criterion2(embeddings, outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, EPOCHS, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b500f1",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b179dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        _, outputs = classic_model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        del images, labels, outputs\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1121602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        embeddings, outputs = combined_model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        del images, labels, outputs\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
