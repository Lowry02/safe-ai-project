{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a137525",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Verified-Intelligence/auto_LiRPA\n",
    "!pip install ./auto_LiRPA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d0a25f",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9e631c",
   "metadata": {},
   "source": [
    "Let's import the needed modules and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556ea434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import tempfile\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from auto_LiRPA import BoundedModule\n",
    "from model import CNNCrown, Encoder, LinearClassifier\n",
    "from verifier import PGDVerifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65a2f1e-5c95-4cc8-91a4-0c87e3c30f27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T22:22:46.876089Z",
     "iopub.status.busy": "2026-01-28T22:22:46.875624Z",
     "iopub.status.idle": "2026-01-28T22:22:46.879855Z",
     "shell.execute_reply": "2026-01-28T22:22:46.879291Z",
     "shell.execute_reply.started": "2026-01-28T22:22:46.876063Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8caed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "BATCH_SIZE = 2048\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8bd9b7-d46f-49b2-87c3-0ca557ef1d52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T22:22:52.854936Z",
     "iopub.status.busy": "2026-01-28T22:22:52.854358Z",
     "iopub.status.idle": "2026-01-28T22:23:00.991504Z",
     "shell.execute_reply": "2026-01-28T22:23:00.990910Z",
     "shell.execute_reply.started": "2026-01-28T22:22:52.854906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "dataset = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=transform)\n",
    "\n",
    "train_ratio, validation_ratio = 0.8, 0.2\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(train_ratio * dataset_size)\n",
    "validation_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, validation_dataset = random_split(dataset, [train_size, validation_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe7f3f4",
   "metadata": {},
   "source": [
    "After that, load all the trained models on the `DEVICE`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc88f305-ea53-40be-935e-6f1e8078402a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T22:22:49.447611Z",
     "iopub.status.busy": "2026-01-28T22:22:49.447050Z",
     "iopub.status.idle": "2026-01-28T22:22:50.437212Z",
     "shell.execute_reply": "2026-01-28T22:22:50.436609Z",
     "shell.execute_reply.started": "2026-01-28T22:22:49.447582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_path = \"models_info/model_weights\"\n",
    "augmentation_path = f\"{base_path}/augmentation\"\n",
    "no_augmentation_path = f\"{base_path}/no_augmentation\"\n",
    "\n",
    "# loading no certified models\n",
    "models_weights = [\n",
    "    torch.load(f\"{augmentation_path}/normal_model.pt\", map_location=DEVICE),\n",
    "    torch.load(f\"{augmentation_path}/contrastive_model.pt\", map_location=DEVICE),\n",
    "    torch.load(f\"{augmentation_path}/adversarial_model.pt\", map_location=DEVICE),\n",
    "    torch.load(f\"{augmentation_path}/adversarial_contrastive_model.pt\", map_location=DEVICE),\n",
    "    torch.load(f\"{no_augmentation_path}/normal_model.pt\", map_location=DEVICE),\n",
    "    torch.load(f\"{no_augmentation_path}/contrastive_model.pt\", map_location=DEVICE),\n",
    "    torch.load(f\"{no_augmentation_path}/adversarial_model.pt\", map_location=DEVICE),\n",
    "    torch.load(f\"{no_augmentation_path}/adversarial_contrastive_model.pt\", map_location=DEVICE),\n",
    "]\n",
    "\n",
    "models = []\n",
    "\n",
    "for weights in models_weights:\n",
    "    model = CNNCrown(pooling=False)\n",
    "    model.load_state_dict(weights)\n",
    "    model.to(DEVICE)\n",
    "    models.append(model)\n",
    "    \n",
    "# loading certified models by hand\n",
    "\n",
    "# with augmentation\n",
    "certified_encoder = BoundedModule(Encoder(), torch.empty(2, 3, 32, 32))\n",
    "certified_encoder.load_state_dict(torch.load(f\"{augmentation_path}/certified_contrastive_encoder.pt\"))\n",
    "certified_classifier = LinearClassifier()\n",
    "certified_classifier.load_state_dict(torch.load(f\"{augmentation_path}/certified_contrastive_classifier.pt\"))\n",
    "certified_contrastive_model = CNNCrown()\n",
    "certified_contrastive_model.encoder = certified_encoder\n",
    "certified_contrastive_model.classifier = certified_classifier\n",
    "models[4:4] = [certified_contrastive_model]    # the models trained using augmentation are in the first part of the list\n",
    "\n",
    "certified_model = BoundedModule(CNNCrown(), torch.empty(2, 3, 32, 32))\n",
    "certified_model.load_state_dict(torch.load(f\"{augmentation_path}/certified_model.pt\"))\n",
    "models[4:4] = [certified_model]    # the models trained using augmentation are in the first part of the list\n",
    "\n",
    "# no augmentation\n",
    "certified_model = BoundedModule(CNNCrown(), torch.empty(2, 3, 32, 32))\n",
    "certified_model.load_state_dict(torch.load(f\"{no_augmentation_path}/certified_model.pt\"))\n",
    "certified_model.to(DEVICE)\n",
    "models.append(certified_model)    # the models trained using no augmentation are in the last part of the list\n",
    "\n",
    "certified_encoder = BoundedModule(Encoder(), torch.empty(2, 3, 32, 32))\n",
    "certified_encoder.load_state_dict(torch.load(f\"{no_augmentation_path}/certified_contrastive_encoder.pt\"))\n",
    "certified_classifier = LinearClassifier()\n",
    "certified_classifier.load_state_dict(torch.load(f\"{no_augmentation_path}/certified_contrastive_classifier.pt\"))\n",
    "certified_contrastive_model = CNNCrown()\n",
    "certified_contrastive_model.encoder = certified_encoder\n",
    "certified_contrastive_model.classifier = certified_classifier\n",
    "certified_contrastive_model.to(DEVICE)\n",
    "models.append(certified_contrastive_model)    # the models trained using no augmentation are in the last part of the list\n",
    "\n",
    "models_name = [\"Normal Model\", \"Contrastive Model\", \"Adversarial Model\", \"Adversarial Contrastive\", \"Certified\", \"Certified Contrastive\"] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a85891-db5e-4fcc-b7fb-0f9e368abc80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T22:23:11.957163Z",
     "iopub.status.busy": "2026-01-28T22:23:11.956859Z",
     "iopub.status.idle": "2026-01-28T22:23:11.961125Z",
     "shell.execute_reply": "2026-01-28T22:23:11.960540Z",
     "shell.execute_reply.started": "2026-01-28T22:23:11.957138Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "epsilon_list = [1/255, 2/255, 4/255, 8/255, 16/255]\n",
    "epsilon_labels = [\"1/255\", \"2/255\", \"4/255\", \"8/255\", \"16/255\"]\n",
    "MAX_POINTS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8c6581",
   "metadata": {},
   "source": [
    "# PGD Verifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8964b89f",
   "metadata": {},
   "source": [
    "This cell evaluates multiple models under a PGD attack across different ε values, computing the **Attack Success Rate (ASR)** on the test set.  \n",
    "For ε = 4/255, it also collects a fixed number of adversarial (or remaining robust) examples per model for later analysis or visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee98258-190f-4fd1-aa3a-09fd5984d2a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T22:23:18.671485Z",
     "iopub.status.busy": "2026-01-28T22:23:18.670926Z",
     "iopub.status.idle": "2026-01-28T22:33:45.956367Z",
     "shell.execute_reply": "2026-01-28T22:33:45.955539Z",
     "shell.execute_reply.started": "2026-01-28T22:23:18.671458Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_images = []\n",
    "\n",
    "pgd = PGDVerifier(DEVICE)\n",
    "print(\"> ASR = Attack Success Rate\\n\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for epsilon, eps_label in zip(epsilon_list, epsilon_labels):\n",
    "        \n",
    "        print(f\"> Eps: {eps_label}\")\n",
    "        eps_list = []\n",
    "        \n",
    "        for model, model_name in zip(models, models_name):\n",
    "            print(f\"\\t> {model_name}\")\n",
    "            model.eval()\n",
    "\n",
    "            model_images_list = []\n",
    "            model_labels_list = []\n",
    "            \n",
    "            images_counter = torch.tensor(0, device=DEVICE)\n",
    "            test_adv_attack_success = torch.tensor(0, device=DEVICE)\n",
    "            total_images = torch.tensor(0, device=DEVICE)\n",
    "            \n",
    "            for images, labels in test_loader:\n",
    "                images = images.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "                \n",
    "                adversarial_examples, successes, initial_wrong_predictions = pgd.verify(\n",
    "                    model, \n",
    "                    images, \n",
    "                    labels, \n",
    "                    epsilon=epsilon,\n",
    "                    alpha=epsilon/2, # more fair for comparison\n",
    "                    clamp_min=-1, # clamp_* -> ensure valid input within [-1,1]\n",
    "                    clamp_max=1\n",
    "                )\n",
    "\n",
    "                if epsilon == 4/255:\n",
    "                    initial_right_predictions = ~initial_wrong_predictions\n",
    "                    adv_indices = torch.logical_and(~successes, initial_right_predictions)\n",
    "                    max_left = MAX_POINTS - images_counter\n",
    "                        \n",
    "                    adv_images = images[adv_indices][:max_left]\n",
    "                    adv_labels = labels[adv_indices][:max_left]\n",
    "    \n",
    "                    if adv_images.numel() > 0:\n",
    "                        model_images_list.append(adv_images)\n",
    "                        model_labels_list.append(adv_labels)\n",
    "                        images_counter += adv_images.shape[0]\n",
    "                    \n",
    "                test_adv_attack_success += successes.sum().item()\n",
    "                total_images += successes.shape[0] - initial_wrong_predictions.sum()\n",
    "\n",
    "            # stack per model\n",
    "            if epsilon == 4/255:\n",
    "                model_images = torch.cat(model_images_list, dim=0)\n",
    "                model_labels = torch.cat(model_labels_list, dim=0)\n",
    "\n",
    "                eps_list.append((model_images, model_labels))\n",
    "                    \n",
    "            test_adv_attack_success = 100 * test_adv_attack_success / total_images\n",
    "            print(f\"\\t\\t- Test ASR: {test_adv_attack_success}%;\")\n",
    "\n",
    "        if epsilon == 4/255:\n",
    "            all_images.append(eps_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9294016c",
   "metadata": {},
   "source": [
    "# $\\alpha\\beta$-CROWN Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc5331b",
   "metadata": {},
   "source": [
    "This cell runs **formal robustness verification ($\\alpha\\beta$-Crown)** on a fixed set of selected images for each of the first four models.  \n",
    "For every image, verification is executed in an isolated subprocess and the resulting robustness status is collected per model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250b03e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_one_point_subprocess(model, image, label, epsilon, device=\"cuda\"):\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        model_path = os.path.join(tmpdir, \"model.pt\")\n",
    "        image_path = os.path.join(tmpdir, \"image.pt\")\n",
    "\n",
    "        torch.save(model, model_path)\n",
    "        torch.save(image.cpu(), image_path)\n",
    "\n",
    "        cmd = [\n",
    "            sys.executable,\n",
    "            \"verify_point.py\",\n",
    "            \"--model_path\", model_path,\n",
    "            \"--image_path\", image_path,\n",
    "            \"--label\", str(int(label)),\n",
    "            \"--epsilon\", str(float(epsilon)),\n",
    "            \"--device\", device,\n",
    "        ]\n",
    "\n",
    "        result = subprocess.run(\n",
    "            cmd,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=False\n",
    "        )\n",
    "\n",
    "        return result.stdout.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909228b1-46b8-4654-be14-1f1e34c0b93e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T23:28:14.770380Z",
     "iopub.status.busy": "2026-01-28T23:28:14.769910Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "outputs = [[] for _ in models[:4]]\n",
    "\n",
    "for model_id, model in enumerate(models[:4]):\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(MAX_POINTS):\n",
    "        image = all_images[0][model_id][0][i]\n",
    "        label = all_images[0][model_id][1][i]\n",
    "\n",
    "        status = verify_one_point_subprocess(\n",
    "            model=model,\n",
    "            image=image,\n",
    "            label=label,\n",
    "            epsilon=epsilon_list[1],\n",
    "            device=DEVICE,\n",
    "        )\n",
    "        status = status.split(\"\\n\")[-1]\n",
    "\n",
    "        outputs[model_id].append(status)\n",
    "        print(\"OK\", models_name[model_id], i, status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bb89cf-8d58-4fa8-bcb9-fd55cbb5ac78",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to store the frequency of statuses for each model\n",
    "status_frequency = {}\n",
    "\n",
    "# Iterate over the outputs and models_name\n",
    "for model_name, output in zip(models_name[:4], outputs[:4]):\n",
    "    # Count the frequency of each status in the output\n",
    "    status_frequency[model_name] = dict(Counter(output))\n",
    "\n",
    "print(status_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb88521-811e-4d48-9325-359721805079",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define all possible labels\n",
    "all_labels = ['safe', 'verified', 'unsafe-pgd', 'unsafe-bab', 'safe-incomplete', 'unknown']\n",
    "label_indices = range(len(all_labels))\n",
    "\n",
    "for model_id, output in enumerate(outputs[:4]):\n",
    "    # Map outputs to indices based on all_labels\n",
    "    output_indices = [all_labels.index(label) for label in output]\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(output_indices, bins=range(len(all_labels) + 1), align='left', rwidth=0.8)\n",
    "    plt.title(f\"Histogram of Labels for Model {models_name[model_id]}\")\n",
    "    plt.xlabel(\"Labels\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xticks(label_indices, all_labels, rotation=45)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f080b6b6",
   "metadata": {},
   "source": [
    "For both `certified_model` and `certified_contrastive_model`, we used the command-line to perform robust verification with $\\alpha\\beta$-CROWN, as it did not work with our script."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelId": 572466,
     "modelInstanceId": 559886,
     "sourceId": 734558,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
