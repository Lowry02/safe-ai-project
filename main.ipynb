{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf3cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c23e787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import CNN\n",
    "from supconloss import SupCon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f0a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc61658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # TODO: add transformations/augmentations?\n",
    "\n",
    "dataset = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=transform)\n",
    "\n",
    "train_ratio, validation_ratio = 0.8, 0.2\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(train_ratio * dataset_size)\n",
    "validation_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, validation_dataset = random_split(dataset, [train_size, validation_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "\n",
    "test_data = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8288c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it = iter(train_loader) # create an iterator over the DataLoader\n",
    "# first = next(it)\n",
    "# print(first[1]) # in position [1], we get the vector of the labels of the batch\n",
    "# second = next(it)\n",
    "# print(second[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9526780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {0: \"Airplane\", 1: \"Automobile\", 2: \"Bird\", 3: \"Cat\", 4: \"Deer\",\n",
    "    5: \"Dog\", 6: \"Frog\", 7: \"Horse\", 8: \"Ship\", 9: \"Truck\",}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(dataset), size=(1,)).item()\n",
    "    img, label = dataset[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5803fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae24f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.dataset.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72b1677",
   "metadata": {},
   "source": [
    "`training_data` is the Dataset, whereas `train_loader` is the wrapper around the Dataset and it controls how data is delivered by creating mini-batches, shuffling, workers, iterating, ... $\\rightarrow$ `train_loader.dataset` is the Dataset  \n",
    "The dataset is composed of pairs of (image, class), where the image is a matrix of pixels and the class $\\in \\{0,9\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d857c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.dataset[15][1] # class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355dd019",
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_model = CNN().to(DEVICE)\n",
    "combined_model = CNN().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670be792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer1 = optim.SGD(classic_model.parameters(), lr=0.01, momentum = 0.9)\n",
    "optimizer2 = optim.SGD(combined_model.parameters(), lr=0.01, momentum = 0.9)\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "criterion2 = SupCon()\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09e595b",
   "metadata": {},
   "source": [
    "Allora, l'idea e' quella di implementare la contrastive loss. Cio' significa ridurre la distanza tra vettori simili e aumentare la distanza tra vettori diversi $\\rightarrow$ loss in funzione della distanza tra i due vettori: se appartenenti alla stessa classe e bassa distanza, loss bassa, e viceversa\n",
    "Contrastive Loss: $$ L_{i, j} = -\\log \\frac{\\exp(sim(z_i, z_j) / \\tau)}{\\sum_{k\\neq i}\\exp(sim(z_i, z_k) / \\tau)}, \\quad\\quad\\quad \\text{where } sim(z_i, z_j) = \\frac{z_i\\cdot z_j}{||z_i|| \\ ||z_j||} $$\n",
    "\n",
    "SCHERZONE QUESTA Ãˆ la NT-XENT nooooooo  \n",
    "Noi vogliamo la SupCon: $$ \\mathcal L_i = {-1\\over |P(i)|}\\sum_{p\\in P(i)}\\log \\frac{\\exp(sim(z_i, z_p) / \\tau)}{\\sum_{a\\neq i}\\exp(sim(z_i, z_a) / \\tau)}, $$ where $P(i)$ is the set of positives for anchor $i$.\n",
    "$\\rightarrow$ final loss: $$ L = {1\\over B}\\sum_i L_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader): # iterating over all the batches\n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        optimizer1.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = classic_model(images)\n",
    "        loss = criterion1(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, EPOCHS, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db859e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader): # iterating over all the batches\n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        optimizer2.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = combined_model(images)\n",
    "        loss = criterion2(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, EPOCHS, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b179dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        outputs = classic_model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        del images, labels, outputs\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
