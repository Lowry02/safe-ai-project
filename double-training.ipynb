{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WiZjBFb9YkHc"
      },
      "outputs": [],
      "source": [
        "from losses import SupConLoss, HingeLoss\n",
        "from model import Encoder, LinearClassifier, CNN\n",
        "from train import train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kzooQDi8Y5LW"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "import umap\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Literal\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kiCH1cVxZadH"
      },
      "outputs": [],
      "source": [
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        # NVIDIA GPU\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(f\"Using CUDA: {torch.cuda.get_device_name(0)}\")\n",
        "    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
        "        # Apple Silicon GPU (MPS)\n",
        "        device = torch.device(\"mps\")\n",
        "        print(\"Using MPS (Apple Silicon GPU)\")\n",
        "    else:\n",
        "        # Fallback to CPU\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"Using CPU\")\n",
        "    return device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPGo5FDrZb15",
        "outputId": "888146f8-7f4d-445f-ed42-d5eb181b4154"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using MPS (Apple Silicon GPU)\n"
          ]
        }
      ],
      "source": [
        "DEVICE = get_device()\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 20\n",
        "PROJ_DIM = 128\n",
        "MODEL_FILENAME = \"custom_model.pt\"\n",
        "TYPE_OF_LOSS:Literal[\"crossentropy\", \"hinge\"] = \"hinge\"  # loss used for the encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RfIHtNRrZdFE"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "]) # TODO: add transformations/augmentations?\n",
        "\n",
        "dataset = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=transform)\n",
        "\n",
        "train_ratio, validation_ratio = 0.8, 0.2\n",
        "dataset_size = len(dataset)\n",
        "train_size = int(train_ratio * dataset_size)\n",
        "validation_size = dataset_size - train_size\n",
        "\n",
        "train_dataset, validation_dataset = random_split(dataset, [train_size, validation_size])\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
        "\n",
        "test_data = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
        "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rovSzx1vqBpN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /Users/lorenzocusin/.netrc.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlorenzocusin02\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.24.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/lorenzocusin/Documents/Uni/master/safe_ai/progetto/wandb/run-20260125_201932-46u35iqa</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lorenzocusin02/Cnn-Verification/runs/46u35iqa' target=\"_blank\">Encoder - SupConLearning</a></strong> to <a href='https://wandb.ai/lorenzocusin02/Cnn-Verification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/lorenzocusin02/Cnn-Verification' target=\"_blank\">https://wandb.ai/lorenzocusin02/Cnn-Verification</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/lorenzocusin02/Cnn-Verification/runs/46u35iqa' target=\"_blank\">https://wandb.ai/lorenzocusin02/Cnn-Verification/runs/46u35iqa</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "&lt;wandb.sdk.wandb_run.Run object at 0x11c238400&gt;"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x11c238400>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sup_con_loss = SupConLoss()\n",
        "encoder = Encoder(in_channels=3, proj_dim=PROJ_DIM).to(DEVICE)\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.init(\n",
        "    project=\"Cnn-Verification\",\n",
        "    name=\"Encoder - SupConLearning\",\n",
        "    config={\n",
        "        \"learning_rate\": 0.01,\n",
        "        \"epochs\": 40,\n",
        "        \"batch_size\": 512,\n",
        "        \"projection_dimension\": 128\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8_xdaybqBpN",
        "outputId": "f50dcdfb-aa30-4ab0-ec03-ba731b4df61b"
      },
      "outputs": [],
      "source": [
        "encoder = train(\n",
        "    encoder,\n",
        "    train_loader,\n",
        "    validation_loader,\n",
        "    encoder_optimizer,\n",
        "    sup_con_loss,\n",
        "    EPOCHS,\n",
        "    DEVICE,\n",
        "    compute_accuracy=False,\n",
        "    wandb_logging=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# show embedding distribution\n",
        "encoder.eval()\n",
        "\n",
        "all_embeddings = []\n",
        "all_labels = []\n",
        "\n",
        "N_ITERATIONS = 500 // BATCH_SIZE\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        embeddings = encoder(images)\n",
        "\n",
        "        all_embeddings.append(embeddings.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "        \n",
        "        if i >= N_ITERATIONS:\n",
        "            break\n",
        "\n",
        "embeddings = torch.cat(all_embeddings, dim=0).numpy()\n",
        "labels = torch.cat(all_labels, dim=0).numpy()\n",
        "\n",
        "# umap computation\n",
        "umap_reducer = umap.UMAP(\n",
        "    n_components=2,\n",
        "    n_neighbors=15,\n",
        "    min_dist=0.1,\n",
        "    metric=\"euclidean\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "embeddings_2d = umap_reducer.fit_transform(embeddings)\n",
        "\n",
        "# plotting\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "scatter = plt.scatter(\n",
        "    embeddings_2d[:, 0],\n",
        "    embeddings_2d[:, 1],\n",
        "    c=labels,\n",
        "    cmap=\"tab10\",\n",
        "    s=5\n",
        ")\n",
        "plt.title(\"UMAP of Embeddings\")\n",
        "plt.colorbar(scatter, ticks=range(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "wandb.log({\n",
        "    \"sample_image\": wandb.Image(plt, caption=\"Embedding distribution\")\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Encoder - SupConLearning</strong> at: <a href='https://wandb.ai/lorenzocusin02/Cnn-Verification/runs/46u35iqa' target=\"_blank\">https://wandb.ai/lorenzocusin02/Cnn-Verification/runs/46u35iqa</a><br> View project at: <a href='https://wandb.ai/lorenzocusin02/Cnn-Verification' target=\"_blank\">https://wandb.ai/lorenzocusin02/Cnn-Verification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20260125_201932-46u35iqa/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8sLsSnBz3GF"
      },
      "outputs": [],
      "source": [
        "hinge_loss = HingeLoss(margin=1)\n",
        "cross_entropy_loss = nn.CrossEntropyLoss()\n",
        "classifier = LinearClassifier(in_dim=PROJ_DIM, num_classes=10).to(DEVICE)\n",
        "classifier_optimizer = optim.Adam(classifier.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "93cjIpe5qBpN",
        "outputId": "d32af472-5bb9-4ba1-9349-60b0ebfc4c6e"
      },
      "outputs": [],
      "source": [
        "def execute_classifier(images:torch.Tensor, labels:torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "    encoder.eval()\n",
        "    with torch.no_grad():\n",
        "        embeddings = encoder(images)\n",
        "    return embeddings, labels\n",
        "\n",
        "classifier = train(\n",
        "    classifier,\n",
        "    train_loader,\n",
        "    validation_loader,\n",
        "    classifier_optimizer,\n",
        "    cross_entropy_loss if TYPE_OF_LOSS == \"crossentropy\" else hinge_loss,\n",
        "    EPOCHS,\n",
        "    DEVICE,\n",
        "    middleware=execute_classifier,\n",
        "    wandb_logging=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJGHyjo6qBpN"
      },
      "outputs": [],
      "source": [
        "model = CNN.import_from(encoder, classifier)\n",
        "torch.save(model.state_dict(), MODEL_FILENAME)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
